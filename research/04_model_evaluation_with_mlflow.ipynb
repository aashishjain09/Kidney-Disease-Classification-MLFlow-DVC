{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d319ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"\"\n",
    "\n",
    "# RUN IN TERMINAL\n",
    "# export MLFLOW_TRACKING_URI = \"\"\n",
    "# export MLFLOW_TRACKING_USERNAME = \"\"\n",
    "# export MLFLOW_TRACKING_PASSWORD = \"\"\n",
    "# python script.py\n",
    "\n",
    "# import tensorflow as tf\n",
    "# model = tf.keras.models.load_model(\"artifacts/training/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468cc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=\"artifacts/training/model.h5\",\n",
    "            training_data=\"artifacts/data_ingestion/kidney-ct-scan-image\",\n",
    "            mlflow_uri=\"\",  # TODO: CHANGE THIS AFTER USING DAGS\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, mlflow, mlflow.keras\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, config=EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _valid_generator(self):\n",
    "        datagenerator_kwargs = dict(rescale=1./255, validation_split=0.30)\n",
    "        dataflow_kwargs = dict(target_size=self.config.params_image_size[:-1], batch_size=self.config.params_batch_size, interpolation=\"bilinear\")\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(directory=self.config.training_data, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "    \n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._valid_generator()\n",
    "        self.score = model.evaluate(self.valid_generator)\n",
    "        self.save_score()\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_score = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param(self.config.all_params)\n",
    "            mlflow.log_metrics({\"loss\": self.score[0], \"accuracy\": self.score[1]})\n",
    "\n",
    "            if tracking_url_type_score != \"file\":\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    evaluation = Evaluation(ConfigurationManager().get_evaluation_config())\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
